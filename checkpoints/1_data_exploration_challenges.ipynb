{"cells":[{"cell_type":"markdown","metadata":{"id":"s8fhxlKY3G09"},"source":["# A quick recap on Pandas DataFrames\n","\n","Pandas DataFrames are mutable two-dimensional structures of data with labeled axes where:\n","* each row represents a different observation\n","* each column represents a different variable\n","\n","As always, we first need to import the Pandas module:"],"id":"s8fhxlKY3G09"},{"cell_type":"code","execution_count":null,"metadata":{"id":"-TpFexIq3G1B"},"outputs":[],"source":["import pandas as pd"],"id":"-TpFexIq3G1B"},{"cell_type":"markdown","metadata":{"id":"dxOHIz6E3G1F"},"source":["## 1.&nbsp; Import a csv file to DataFrame\n","\n","Most of the time, you will not be creating DataFrames yourself, but importing (or \"reading\") data from a csv file or a database into a pandas DataFrame. It's easy to do with pandas' read functions. We will read one of the datasets from the Eniac project, which we have stored in a Google Drive folder:"],"id":"dxOHIz6E3G1F"},{"cell_type":"code","execution_count":null,"metadata":{"id":"jy28BixO3G1G"},"outputs":[],"source":["url = \"https://drive.google.com/file/d/1FYhN_2AzTBFuWcfHaRuKcuCE6CWXsWtG/view?usp=sharing\" # orderlines.csv\n","path = \"https://drive.google.com/uc?export=download&id=\"+url.split(\"/\")[-2]\n","df = pd.read_csv(path)"],"id":"jy28BixO3G1G"},{"cell_type":"code","source":["df"],"metadata":{"id":"d5kYr9zgqbRT"},"id":"d5kYr9zgqbRT","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UXNi42Dd3G1G"},"source":["## 2.&nbsp; DataFrame dimensions\n","\n","With the [DataFrame.shape](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html) attribute we can calculate the dimensions (number of rows and columns) of the DataFrame."],"id":"UXNi42Dd3G1G"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXXpy1VLdz-w"},"outputs":[],"source":["df"],"id":"cXXpy1VLdz-w"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnC6vIW93G1G"},"outputs":[],"source":["df.shape"],"id":"cnC6vIW93G1G"},{"cell_type":"markdown","metadata":{"id":"5oLX6uZQ3G1H"},"source":["As a result we obtain a [tuple](https://www.w3schools.com/python/python_tuples.asp) where the first element is the number of rows, which in our case is 293983, while the second element is the number of columns, which in our example was 7."],"id":"5oLX6uZQ3G1H"},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6FAi4DN3G1H"},"outputs":[],"source":["nrows = df.shape[0]\n","ncols = df.shape[1]\n","print(\"The number of rows is\", nrows)\n","print(\"The number of columns is\", ncols)"],"id":"L6FAi4DN3G1H"},{"cell_type":"markdown","metadata":{"id":"RjHf6uXq3G1H"},"source":["[DataFrame.size](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.size.html) returns the total number of values that the DataFrame has (the number of rows multiplied by the number of columns):"],"id":"RjHf6uXq3G1H"},{"cell_type":"code","execution_count":null,"metadata":{"id":"mHVz_-yA3G1H"},"outputs":[],"source":["df.size"],"id":"mHVz_-yA3G1H"},{"cell_type":"markdown","metadata":{"id":"ncyEOZxWJvHj"},"source":["We can check if the `.size` and `.shape` agree"],"id":"ncyEOZxWJvHj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_8Y1rsD3G1H"},"outputs":[],"source":["df.shape[0] * df.shape[1] == df.size"],"id":"t_8Y1rsD3G1H"},{"cell_type":"markdown","metadata":{"id":"d9_rKAd13G1I"},"source":["With the [DataFrame.ndim](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ndim.html) attribute we calculate the number of dimensions that the DataFrame has. This will always be 2, as it consists of rows and columns."],"id":"d9_rKAd13G1I"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OkKrVfnB3G1I"},"outputs":[],"source":["df.ndim"],"id":"OkKrVfnB3G1I"},{"cell_type":"markdown","metadata":{"id":"HWSKDRiF3G1I"},"source":["## 3.&nbsp; DataFrames exploration\n","\n","The [DataFrame.head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) and [DataFrame.tail()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html) methods are used to display the first or last rows of the DataFrame. Looking at the raw data is a great way to get a grasp of what's in there. By default, 5 rows will be shown, but you can change that:"],"id":"HWSKDRiF3G1I"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEn0y8Wv3G1I"},"outputs":[],"source":["df.head()"],"id":"eEn0y8Wv3G1I"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6IJWPJqr3G1I"},"outputs":[],"source":["df.head(9)"],"id":"6IJWPJqr3G1I"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9JMHjCMs3G1J"},"outputs":[],"source":["df.tail()"],"id":"9JMHjCMs3G1J"},{"cell_type":"markdown","metadata":{"id":"-JQjo2ZD3G1J"},"source":["The methods [DataFrame.info()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html), [DataFrame.describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) and [DataFrame.nunique()](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.nunique.html) give a general overview of what's in the DataFrame:"],"id":"-JQjo2ZD3G1J"},{"cell_type":"markdown","metadata":{"id":"lNgOc5RpIszg"},"source":["`.info()` tells us about how pandas sees the data - how it is stored, whether there's any missing values, and how many columns and rows we have."],"id":"lNgOc5RpIszg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8N7pC22c3G1J"},"outputs":[],"source":["df.info()"],"id":"8N7pC22c3G1J"},{"cell_type":"markdown","metadata":{"id":"B4zDaO3zIx6_"},"source":["`.describe()` gives us an overview of the [descriptive statistics](https://www.scribbr.com/statistics/descriptive-statistics/) for the numerical columns of our DataFrame."],"id":"B4zDaO3zIx6_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYp_rSRa3G1J"},"outputs":[],"source":["df.describe()"],"id":"uYp_rSRa3G1J"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXMZsav-3G1J"},"outputs":[],"source":["df.nunique()"],"id":"cXMZsav-3G1J"},{"cell_type":"markdown","metadata":{"id":"MiUZS2983G1J"},"source":["If we wish, we can also view the unique values counted by `series.nunique()`. The [.unique()](https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html) method returns the unique values from a column as a numpy array, which can be indexed with `[]`:"],"id":"MiUZS2983G1J"},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vwHHjvR3G1K"},"outputs":[],"source":["df[\"sku\"].unique()[:10]"],"id":"-vwHHjvR3G1K"},{"cell_type":"markdown","metadata":{"id":"gr9AteWL3G1K"},"source":["The [DataFrame.isna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) method returns a boolean for each value: `True` if that value is \"missing\" (which is represented as `NaN` in numpy and pandas) and `False` if the value is not missing:"],"id":"gr9AteWL3G1K"},{"cell_type":"code","execution_count":null,"metadata":{"id":"tILEtcSP3G1K"},"outputs":[],"source":["df.isna()"],"id":"tILEtcSP3G1K"},{"cell_type":"markdown","metadata":{"id":"TduVg5qx3G1K"},"source":["We can then use [DataFrame.sum()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html) to add up all these booleans for each column, and count how many missing values are there in the DataFrame, since `True` is interpreted as `1` and `False` as `0`:"],"id":"TduVg5qx3G1K"},{"cell_type":"code","execution_count":null,"metadata":{"id":"vd-_DsOy3G1K"},"outputs":[],"source":["df.isna().sum()"],"id":"vd-_DsOy3G1K"},{"cell_type":"markdown","metadata":{"id":"CsDhKqdG3G1K"},"source":["[DataFrame.duplicated()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html) also returns a boolean output, but in this case just one value per row: `True` if that row is duplicated and `False` if it's not. Again, using `sum()` allows us to count how many `True` values (i.e. duplicated rows) are there in total:"],"id":"CsDhKqdG3G1K"},{"cell_type":"code","execution_count":null,"metadata":{"id":"vE-E_D2i3G1K"},"outputs":[],"source":["df.duplicated().sum()"],"id":"vE-E_D2i3G1K"},{"cell_type":"markdown","metadata":{"id":"74PzmnGf3G1K"},"source":["[DataFrame.nlargest(n, columns)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html) will return the top `n` rows with the largest value for whatever column we specify in `columns`. Below, we see the rows with the largest product quantity values:"],"id":"74PzmnGf3G1K"},{"cell_type":"code","execution_count":null,"metadata":{"id":"BJqMsFIn3G1K"},"outputs":[],"source":["df.nlargest(5, \"product_quantity\")"],"id":"BJqMsFIn3G1K"},{"cell_type":"markdown","metadata":{"id":"c6wXOPu83G1L"},"source":["[DataFrame.nsmallest()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html) does the same, for the smallest values:"],"id":"c6wXOPu83G1L"},{"cell_type":"code","execution_count":null,"metadata":{"id":"MskkIhU_3G1L"},"outputs":[],"source":["df.nsmallest(5, \"product_quantity\")"],"id":"MskkIhU_3G1L"},{"cell_type":"markdown","metadata":{"id":"NPaxO3ecXuCO"},"source":["So far, we have seen two ways to explore DataFrames:\n","\n","* **Attributes:** `.shape`, `.size` and `.ndim`, and others. They are written without parentheses and give you raw \"metadata\" about the DataFrame you are calling them on.\n","* **Methods:** `.head()`, `.describe()` and `.isna()`, and others. They are written with parentheses and perform some sort of calculation, transformation or aggregation. A method is like a function that is tied to a specific object type.\n","\n","DataFrames have a lot of attributes and methods and may not be obvious whether something belongs to one type or the other. Whenever in doubt, check [the documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html?highlight=DataFrame#pandas.DataFrame). If you scroll down past the list of examples you will find two sections listing all the attributes and methods."],"id":"NPaxO3ecXuCO"},{"cell_type":"markdown","metadata":{"id":"MFV6C4zW3G1L"},"source":["## 4.&nbsp; Select Columns\n","\n","Given a DataFrame, we can select a particular column in several ways:\n","\n","* Indicating the name of the column between square brackets, `[]`\n","* With the `.loc[]` attribute (by name or tag)\n","* With the `.iloc[]` attribute (by position)"],"id":"MFV6C4zW3G1L"},{"cell_type":"markdown","metadata":{"id":"Z6P2fDJr3G1L"},"source":["Plain square brackets `[]` are used to just view a column if you know its name and **don't want to modify it**:"],"id":"Z6P2fDJr3G1L"},{"cell_type":"code","execution_count":null,"metadata":{"id":"IKK6Fucf3G1L"},"outputs":[],"source":["df[\"id_order\"]"],"id":"IKK6Fucf3G1L"},{"cell_type":"markdown","metadata":{"id":"Hwd-yBuB3G1L"},"source":["`.loc[]` takes two arguments: `[rows, columns]`. Passing `:` to the rows argument means \"grabbing all the rows\", which allows you to select a whole column, if you know its name. This method is more flexible as you will see in the future, and allows you to modify the data.\n","\n","We recommend using `loc[]` as the primary option for selecting data."],"id":"Hwd-yBuB3G1L"},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYwX2tQU3G1L"},"outputs":[],"source":["df.loc[:, \"id_order\"]"],"id":"qYwX2tQU3G1L"},{"cell_type":"markdown","metadata":{"id":"2gTOrkQh3G1L"},"source":["`.iloc[]` works similarly to `.loc[]`, but it only accepts integers, which represent the positions of the rows and columns:"],"id":"2gTOrkQh3G1L"},{"cell_type":"code","execution_count":null,"metadata":{"id":"51vu5OgL3G1L"},"outputs":[],"source":["df.iloc[:, 1]"],"id":"51vu5OgL3G1L"},{"cell_type":"markdown","metadata":{"id":"mCG96SJS3G1M"},"source":["### 4.1.&nbsp; Select multiple columns\n","\n","If we want to select more than one column, we can do it with all the options listed above, with slight modifications in some cases:\n","\n","> **Note:** we pass a list inside of the `[]`, a list is also represented by `[]`, hence why we have 2 sets of square brackets"],"id":"mCG96SJS3G1M"},{"cell_type":"code","execution_count":null,"metadata":{"id":"nE6QOfSw3G1M"},"outputs":[],"source":["df[[\"id_order\",\"sku\"]]"],"id":"nE6QOfSw3G1M"},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPN9LgVP3G1M"},"outputs":[],"source":["df.loc[:, [\"id_order\", \"sku\"]]"],"id":"sPN9LgVP3G1M"},{"cell_type":"markdown","metadata":{"id":"kFzAPFl23G1M"},"source":["With `.loc[]` and `:` you can select all columns between two columns you specify."],"id":"kFzAPFl23G1M"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ew-dOjYs3G1M"},"outputs":[],"source":["df.loc[:, \"id_order\":\"sku\"]"],"id":"Ew-dOjYs3G1M"},{"cell_type":"code","source":["df.reset_index(inplace=True)\n","df.loc[df['id']==1119110.0]"],"metadata":{"id":"nnhKK-rUx0UV"},"id":"nnhKK-rUx0UV","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vl4yNTak3G1M"},"outputs":[],"source":["df.iloc[:, [1, 4]]"],"id":"vl4yNTak3G1M"},{"cell_type":"code","execution_count":null,"metadata":{"id":"YulMzlS_3G1M"},"outputs":[],"source":["df.iloc[:, 1:5]"],"id":"YulMzlS_3G1M"},{"cell_type":"markdown","metadata":{"id":"t6ff3smA3G1M"},"source":["## 5.&nbsp; Select Rows\n","\n","Selecting rows is easy if you know how to select columns. You have two options:\n","\n","* With `.loc[]` (by name or tag)\n","* With `.iloc[]` (by position)"],"id":"t6ff3smA3G1M"},{"cell_type":"markdown","metadata":{"id":"NONgKdat3G1M"},"source":["Selecting a single row returns a pandas Series (a 1-dimensional object):"],"id":"NONgKdat3G1M"},{"cell_type":"code","source":["df.set_index('id', inplace=True)"],"metadata":{"id":"RZCGJFn1xVrj"},"id":"RZCGJFn1xVrj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"NXs8qpCvxaKT"},"id":"NXs8qpCvxaKT","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1VMW2DjU3G1N"},"outputs":[],"source":["df.loc[0, :]"],"id":"1VMW2DjU3G1N"},{"cell_type":"markdown","metadata":{"id":"sB8ABuQC3G1N"},"source":["With `.loc[]`, rows are selected by their index name:"],"id":"sB8ABuQC3G1N"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b3x_Zfcn3G1N"},"outputs":[],"source":["df.loc[0:3, :]"],"id":"b3x_Zfcn3G1N"},{"cell_type":"markdown","metadata":{"id":"_UUQqfTT3G1N"},"source":["If we change the index and set it to the `id` column, now the first rows can not be selected the same way:\n","> **Note:** `inplace = True` is the same as doing `df = df.set_index(\"id\")`, i.e. it modifies the DataFrame"],"id":"_UUQqfTT3G1N"},{"cell_type":"code","source":["df.loc[0, 'id'] = None"],"metadata":{"id":"89kiVOGUwhFw"},"id":"89kiVOGUwhFw","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWZkhVd_3G1N"},"outputs":[],"source":["df.set_index(\"id\", inplace=True)"],"id":"ZWZkhVd_3G1N"},{"cell_type":"markdown","metadata":{"id":"rVo5D8FxpjmC"},"source":["Look, the same code as above no longer works. The index has been changed to the `id` column, if we want to use `.loc` we now need to use the names/numbers from `id`"],"id":"rVo5D8FxpjmC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"GfbGU34H3G1N"},"outputs":[],"source":["df.loc[0:3, :]"],"id":"GfbGU34H3G1N"},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2UMedJo3G1N"},"outputs":[],"source":["df.loc[1119109:1119112, :]"],"id":"H2UMedJo3G1N"},{"cell_type":"markdown","metadata":{"id":"n_cOlxFPrEtJ"},"source":["You can always tell the index column as it will be in bold"],"id":"n_cOlxFPrEtJ"},{"cell_type":"markdown","metadata":{"id":"UrwM_2w73G1N"},"source":["With the `.iloc[]` method we don't need to know the row names to select rows at a certain position. Every row and column is instead nominally indexed, starting from the number 0:"],"id":"UrwM_2w73G1N"},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7P8gqaF3G1N"},"outputs":[],"source":["df.iloc[:4]"],"id":"R7P8gqaF3G1N"},{"cell_type":"markdown","metadata":{"id":"UfUYQFZKsf6f"},"source":["We can select the last observation with the method `.iloc[]` by using negative numbers"],"id":"UfUYQFZKsf6f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"q5yP3x7W3G1O"},"outputs":[],"source":["df.iloc[-1]"],"id":"q5yP3x7W3G1O"},{"cell_type":"markdown","metadata":{"id":"siiaQDfvs4rw"},"source":["We can, whenever necessary, reset the index to a set of numbers starting from 0. This would also make the `id` column a normal column once again"],"id":"siiaQDfvs4rw"},{"cell_type":"code","execution_count":null,"metadata":{"id":"DBELgGe_3G1O"},"outputs":[],"source":["df.reset_index(inplace=True)"],"id":"DBELgGe_3G1O"},{"cell_type":"markdown","metadata":{"id":"5C394I2F3G1O"},"source":["Indexing can get tricky sometimes, it's ok to take some time to get used to the methods we presented, and it's ok to have some trouble selecting the rows and columns you need. For an exhaustive guide on Pandas indexing, check out this link: https://pandas.pydata.org/docs/user_guide/indexing.html#indexing"],"id":"5C394I2F3G1O"},{"cell_type":"markdown","metadata":{"id":"nUTQs-aM3G1O"},"source":["## 6.&nbsp; Drop Columns"],"id":"nUTQs-aM3G1O"},{"cell_type":"markdown","metadata":{"id":"I-3vooKB3G1O"},"source":["The `.drop()` method allows us to delete the rows or columns.\n","\n","> **Note:** Again, if we want to directly apply the changes to the original DataFrame, we need to indicate `inplace = True`. Otherwise, we are getting as an output just a \"view\" of how the DataFrame looks like after the drop, but the original DataFrame remains unchanged.\n","\n","> **Note:** `axis=1` means we want to drop a column, not a row. For rows we would use `axis=0`"],"id":"I-3vooKB3G1O"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kXuJacQh3G1O"},"outputs":[],"source":["df.drop(columns=[\"unit_price\"])"],"id":"kXuJacQh3G1O"},{"cell_type":"markdown","metadata":{"id":"LOuOppjLAztn"},"source":["See how our output above shows no column `unit_price`. Then look at the output below, `unit_price` is magically back. We didn't use `inplace=True` above, which means that our output displayed what we asked, but didn't alter the original DataFrame. Be careful of this, Pandas only changes data if you explicitly tell it to do so."],"id":"LOuOppjLAztn"},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7prVCC0XFuQ"},"outputs":[],"source":["df"],"id":"z7prVCC0XFuQ"},{"cell_type":"markdown","metadata":{"id":"4Labqke33G1O"},"source":["## 7.&nbsp; Filter rows based on conditions"],"id":"4Labqke33G1O"},{"cell_type":"markdown","metadata":{"id":"IVYuL86eBxoD"},"source":["Using `.loc` to filter for rows that have a `product_quantity greater than 100`"],"id":"IVYuL86eBxoD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"HRi9zIme3G1O"},"outputs":[],"source":["df.loc[df[\"product_quantity\"] > 100, :]"],"id":"HRi9zIme3G1O"},{"cell_type":"markdown","metadata":{"id":"BHaXdzx53G1P"},"source":["The `.query()` method can be useful for this purpose. Some of you may prefer it as it resembles SQL syntax. You can use any **Python Comparison Operators** you want inside the query method (find more information on this [link](https://www.w3schools.com/python/python_operators.asp)).\n","> **Note:** `.query()` only works when the named column does not contain any white space and string values are contained within a separate set of quotes (the string value may contain white space). For example, if you have a columnÂ `a b` and you wish to query it `df.query(\"a b == 5\")`, this would throw up an error. For column names you should always be using an underscore `_` not a space."],"id":"BHaXdzx53G1P"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Imd3FNA73G1P"},"outputs":[],"source":["df.query(\"product_quantity > 100\")"],"id":"Imd3FNA73G1P"},{"cell_type":"markdown","metadata":{"id":"gsRzSuU63G1P"},"source":["The `isin()` method is very useful to find rows that match any of the values you have **in a list**. For example, here we are searching for rows where its `sku` matches any of the 2 sku's we listed:"],"id":"gsRzSuU63G1P"},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1TEQt9I3G1P"},"outputs":[],"source":["# find out a column that contains a list\n","df[\"sku\"].isin(corrupted_ids)"],"id":"L1TEQt9I3G1P"},{"cell_type":"markdown","metadata":{"id":"YmXRUlSn3G1P"},"source":["This expression can be used inside of `[]` or `.loc[]` to filter the rows that have a `True` value. This is called \"boolean indexing\" and it is really useful:"],"id":"YmXRUlSn3G1P"},{"cell_type":"code","execution_count":null,"metadata":{"id":"atw7-ACt3G1P"},"outputs":[],"source":["df.loc[df[\"sku\"].isin([\"JBL0104\", \"ADN0039\"]), :]"],"id":"atw7-ACt3G1P"},{"cell_type":"markdown","metadata":{"id":"QLwMs-3a3G1P"},"source":["Pandas compresses large outputs in Colab/Jupyter Notebooks. If you want to see more rows, you can change the options:\n","> **Note:** after running this cell, run the code above again and you will see all the rows"],"id":"QLwMs-3a3G1P"},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNETSG7G3G1P"},"outputs":[],"source":["pd.options.display.max_rows = 100"],"id":"mNETSG7G3G1P"},{"cell_type":"markdown","metadata":{"id":"qJhIjHOs3G1P"},"source":["For a complete list of all settings and options that can be tweaked, check out this: https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html"],"id":"qJhIjHOs3G1P"},{"cell_type":"markdown","metadata":{"id":"v6D7KaoD3G1P"},"source":["#### 7.1.&nbsp; Modifying a DataFrame & the `.copy()` method"],"id":"v6D7KaoD3G1P"},{"cell_type":"markdown","metadata":{"id":"zBZAnNeH3G1Q"},"source":["Let's take a small sample of data from our DataFrame:"],"id":"zBZAnNeH3G1Q"},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZXlor-13G1Q"},"outputs":[],"source":["sample = df.iloc[:3,:]\n","sample"],"id":"JZXlor-13G1Q"},{"cell_type":"markdown","metadata":{"id":"swYUYZjt3G1Q"},"source":["Now we pick a single cell from the sample we took and we assign a new value to it. A warning already tells us that this is a risky thing to do:"],"id":"swYUYZjt3G1Q"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ixGPim2Y3G1Q"},"outputs":[],"source":["sample.iloc[0,4] = \"NEW VALUE HERE\""],"id":"ixGPim2Y3G1Q"},{"cell_type":"markdown","metadata":{"id":"U8qhJ9O73G1Q"},"source":["We can see the new value on the `sample` we took:"],"id":"U8qhJ9O73G1Q"},{"cell_type":"code","execution_count":null,"metadata":{"id":"lk8IQI2a3G1Q"},"outputs":[],"source":["sample"],"id":"lk8IQI2a3G1Q"},{"cell_type":"markdown","metadata":{"id":"QJj6Y3dX3G1Q"},"source":["..and, maybe to your surprise, we can see that the new value is also present on the original `df`!"],"id":"QJj6Y3dX3G1Q"},{"cell_type":"code","execution_count":null,"metadata":{"id":"DnuFofL63G1Q"},"outputs":[],"source":["df.head()"],"id":"DnuFofL63G1Q"},{"cell_type":"markdown","metadata":{"id":"hZ39MurF3G1Q"},"source":["When you take a sample of data using `.loc[]` or `iloc[]` and assign it to a new object, the new object is just a \"tag\" pointing to the very same data as the original DataFrame points to. We can avoid this using the method `.copy()`"],"id":"hZ39MurF3G1Q"},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9Cj3-Ol3G1R"},"outputs":[],"source":["import pandas as pd\n","url = \"https://drive.google.com/file/d/1FYhN_2AzTBFuWcfHaRuKcuCE6CWXsWtG/view?usp=sharing\" # orderlines.csv\n","path = \"https://drive.google.com/uc?export=download&id=\"+url.split(\"/\")[-2]\n","df = pd.read_csv(path)"],"id":"n9Cj3-Ol3G1R"},{"cell_type":"code","source":["orderlines_df = df.copy()"],"metadata":{"id":"tD0I-cYX0m6h"},"id":"tD0I-cYX0m6h","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsHuo_10MKdD"},"outputs":[],"source":["sample = df.iloc[:3,:].copy()\n","sample.iloc[0,4] = \"NEW VALUE HERE\"\n","sample"],"id":"MsHuo_10MKdD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Um3hCwSo3G1R"},"outputs":[],"source":["df.head(3)"],"id":"Um3hCwSo3G1R"},{"cell_type":"markdown","metadata":{"id":"5Qt54KJN3G1R"},"source":["As you can see, now it has not been modified."],"id":"5Qt54KJN3G1R"},{"cell_type":"markdown","metadata":{"id":"xI15Yty93G1R"},"source":["# CHALLENGES"],"id":"xI15Yty93G1R"},{"cell_type":"code","source":["import pandas as pd\n","url = \"https://drive.google.com/file/d/1FYhN_2AzTBFuWcfHaRuKcuCE6CWXsWtG/view?usp=sharing\" # orderlines.csv\n","path = \"https://drive.google.com/uc?export=download&id=\"+url.split(\"/\")[-2]\n","df = pd.read_csv(path)"],"metadata":{"id":"65CwwAXmqKvc"},"id":"65CwwAXmqKvc","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jLucFFaF3G1R"},"source":["## Challenge 1:\n","How many different unit prices does the product with the sku JBL0104 have? Combine a pandas filter method with the method `.nunique()`."],"id":"jLucFFaF3G1R"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6OcFknu3G1R"},"outputs":[],"source":["# your code here\n","df.loc[df['sku'] == 'JBL0104', 'unit_price'].nunique()"],"id":"Z6OcFknu3G1R"},{"cell_type":"markdown","metadata":{"id":"r9OJ3Q8e3G1R"},"source":["## Challenge 2:\n","List the (unique) items that were sold in the order with the id_order 385921."],"id":"r9OJ3Q8e3G1R"},{"cell_type":"code","execution_count":null,"metadata":{"id":"89q-PEn9NWpD"},"outputs":[],"source":["# your code here\n","df.loc[df[\"id_order\"] == 385921, 'sku'].nunique()"],"id":"89q-PEn9NWpD"},{"cell_type":"markdown","metadata":{"id":"Hndvnnuy3G1R"},"source":["## Challenge 3:\n","Consider the products with the skus APP2431 and APP2348. Find out in how many orders they were present."],"id":"Hndvnnuy3G1R"},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQB2HCG33G1R"},"outputs":[],"source":["# your code here\n","df.loc[df[\"sku\"].isin([\"APP2431\", \"APP2348\"]), \"id_order\"].nunique()\n","\n","prod_1_ids = set(df.loc[df[\"sku\"] == \"APP2431\", \"id_order\"])\n","prod_2_ids = set(df.loc[df[\"sku\"] == \"APP2348\", \"id_order\"])\n","\n","#orders with APP2431\n","print(f'{len(prod_1_ids)} orders have APP2431 in them')\n","#orders with APP2348\n","print(f'{len(prod_2_ids)} orders have APP2348 in them')\n","#orders with either\n","print(f'{len(prod_1_ids | prod_2_ids)} orders have either APP2348 or APP2431 in them')\n","#orders with both\n","print(f'{len(prod_1_ids & prod_2_ids)} orders have both APP2348 and APP2431 in them')"],"id":"tQB2HCG33G1R"},{"cell_type":"markdown","metadata":{"id":"evf52afz3G1S"},"source":["## Challenge 4:\n","Create a new DataFrame, `df_50`, with all the rows that have a product quantity higher than 500 and only the columns `id`, `product_id`, `product_quantity` and `sku`. Be sure to use the method `.copy()`. Once the new DataFrame is created, modify the column \"product_quantity\" to \"quantity\", and \"sku\" to \"product_code\". To do so, you can use the method `.rename()` or assign a list of new names to the attribute `.columns`."],"id":"evf52afz3G1S"},{"cell_type":"markdown","metadata":{"id":"vwNLziymOj6r"},"source":["Creating `df_50`"],"id":"vwNLziymOj6r"},{"cell_type":"code","execution_count":null,"metadata":{"id":"BN90-eoyBtau"},"outputs":[],"source":["# your code here\n","df_50 = df.loc[df[\"product_quantity\"]>500,[\"id\",\"product_id\",\"product_quantity\",\"sku\"]].copy()\n","df_50"],"id":"BN90-eoyBtau"},{"cell_type":"markdown","metadata":{"id":"6kKDrS5hOmU0"},"source":["Renaming columns of `df_50`"],"id":"6kKDrS5hOmU0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WR4-SUD3MZt6"},"outputs":[],"source":["# your code here\n","df_50 = df_50.rename(columns={\"product_quantity\" : \"quantity\",\n","                              \"sku\" : \"product_code\"})\n","df_50"],"id":"WR4-SUD3MZt6"},{"cell_type":"markdown","source":["Exploration Challenges:"],"metadata":{"id":"Fek-K7H2l6FC"},"id":"Fek-K7H2l6FC"},{"cell_type":"code","source":["# orderlines.csv\n","orderlines_url = \"https://drive.google.com/file/d/1FYhN_2AzTBFuWcfHaRuKcuCE6CWXsWtG/view?usp=sharing\"\n","orders_url = \"https://drive.google.com/file/d/1Vu0q91qZw6lqhIqbjoXYvYAQTmVHh6uZ/view?usp=sharing\"\n","products_url = \"https://drive.google.com/file/d/1afxwDXfl-7cQ_qLwyDitfcCx3u7WMvkU/view?usp=sharing\"\n","brands_url = \"https://drive.google.com/file/d/1XGyabaa4mAkjixMk3XPgx_14OoSse3rs/view?usp=sharing\"\n","\n","def import_csv(url):\n","  path = \"https://drive.google.com/uc?export=download&id=\"+url.split(\"/\")[-2]\n","  return pd.read_csv(path)\n","\n","orderlines_df = import_csv(orderlines_url)\n","orders_df = import_csv(orders_url)\n","products_df = import_csv(products_url)\n","brands_df = import_csv(brands_url)"],"metadata":{"id":"BsI2gxu6l77i"},"id":"BsI2gxu6l77i","execution_count":null,"outputs":[]},{"cell_type":"code","source":["orderlines_df.info()"],"metadata":{"id":"dzn16t8wx9je"},"id":"dzn16t8wx9je","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How many orders are there?"],"metadata":{"id":"j-6B5suym1lN"},"id":"j-6B5suym1lN"},{"cell_type":"code","source":["orderlines_df['id_order'].nunique()"],"metadata":{"id":"Qfg44qVFm_YL"},"id":"Qfg44qVFm_YL","execution_count":null,"outputs":[]},{"cell_type":"code","source":["orders_df['order_id'].nunique()"],"metadata":{"id":"7l1fEvvvvFgv"},"id":"7l1fEvvvvFgv","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How many products are there?"],"metadata":{"id":"6sGWIPg6m8cZ"},"id":"6sGWIPg6m8cZ"},{"cell_type":"code","source":["orderlines_df['sku'].nunique()"],"metadata":{"id":"qixOEdPrvarr"},"id":"qixOEdPrvarr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["products_df['sku'].nunique()"],"metadata":{"id":"ojTkC7Nhm-vl"},"id":"ojTkC7Nhm-vl","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["What period of time do these orders comprise?"],"metadata":{"id":"J56c8Jfxm_rh"},"id":"J56c8Jfxm_rh"},{"cell_type":"code","source":["earliest = orders_df['created_date'].min()\n","latest = orders_df['created_date'].max()\n","print(f'Orders from {earliest} to {latest}')"],"metadata":{"id":"tRdnBPr3nDkK"},"id":"tRdnBPr3nDkK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["earliest = orderlines_df['date'].min()\n","latest = orderlines_df['date'].max()\n","print(f'Orders from {earliest} to {latest}')"],"metadata":{"id":"tNJIOBx1wMUY"},"id":"tNJIOBx1wMUY","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How many orders are Completed?"],"metadata":{"id":"0cy0c64InEAs"},"id":"0cy0c64InEAs"},{"cell_type":"code","source":["orders_df.value_counts('state').plot.bar()"],"metadata":{"id":"or0Z9bAPxIMn"},"id":"or0Z9bAPxIMn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How should revenue be computed?"],"metadata":{"id":"inDWyopanHRz"},"id":"inDWyopanHRz"},{"cell_type":"code","source":["orderlines_df['unit_price'] = pd.to_numeric(orderlines_df['unit_price'])"],"metadata":{"id":"4B1FC8YjxwwB"},"id":"4B1FC8YjxwwB","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Only completed orders\n","orders_df.loc[orders_df['state'] == 'Completed', 'total_paid'].sum()"],"metadata":{"id":"vKL6Y5mgnK9e"},"id":"vKL6Y5mgnK9e","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["HWSKDRiF3G1I","MFV6C4zW3G1L","mCG96SJS3G1M","t6ff3smA3G1M","nUTQs-aM3G1O","v6D7KaoD3G1P"],"provenance":[{"file_id":"1yha4wb3hywOsU6rjrfQRO3VGEvWBJtjQ","timestamp":1733150334255},{"file_id":"1hFHSEy_blfgjYkBcOjdoIypFvtKvK_NP","timestamp":1661242512128},{"file_id":"1fyzS1d-AnL48uaXyCfIUF_0WdBZkckDd","timestamp":1658822216180}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":5}